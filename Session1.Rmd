---
title: 'Geospatial Carpentry: Session 1: Intro to R'
author: "Aleksandra Wilczynska"
date: "2022-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

# Load libraries ----------------------------------------------------------
# Package names
packages <- c("tidyverse", "here")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

```

- [Coordination document](https://docs.google.com/document/d/1x4mRcsSTyUueN_mCiZHE1TOTvF-OZRwq2gV_J9svPRI/edit#heading=h.rv3i711oni3d)
- [Introduction to R for Geospatial Data](https://datacarpentry.org/r-intro-geospatial/)

<!-- need to reduce this part by  15 minutes -> to 80 minutes -->

# [Introduction to  RStudio](https://datacarpentry.org/r-intro-geospatial/01-rstudio-intro/index.html) and [Project management](https://datacarpentry.org/r-intro-geospatial/02-project-intro/index.html) (35 min)

## Why R?

- It is a **free** and **open-source** programming language/software! 
- It was created by statisticians for **statistics** 
- It's script-based, hence great for **reproducibility** 

## Why RStudio?
 *I might remove that part*
- RStudio is an integrated development environment (IDE)
- It provides a (much prettier) interface for the R software
- R is integrated into RStudio, so you never actually have to open R 

## Default layout

- Entire Left / Bottom Left : **R console** (what R would look and be like without RStudio)
- Top right: **Environment/History** (look here to see what you have done)
- Bottom Right: Files/Plots/Packages/Help/Viewer (see the contents of the project/working directory)

![](assets/img/01-rstudio.png)

- Top left: Once you open files, such as R scripts, an editor panel will also open in the top left.

![](assets/img/02-rstudio.png)

## Interacting with R

### Two main ways to interact with R

+ Test and play within the interactive R console 
    + Pros: immediate results
    + Cons: work lost once we close RStudio
+ Start writing in an .R file
    + File still will be executed in the console
    + Pros: complete record of what you did!
    - Cons?

### Running the code
+ In the console: `Enter`
+ In the script:
   + `Ctrl` + `Enter` 
   + `Run` button on right left - current line or selection

### Escaping 
The console shows it's ready to get new commands with `>` sign. It will show `+` sign if it still requires input for the command to be executed. 

Sometimes you don't know what is missing/ you change your mind and want to run something else, or your code is running much too long and you just want it to stop. The way to do it is to hit `Esc`.

## Project managament 
R Studio gives a functionality of creating projects: self-contained working space (i.e. working directory), to which R will refer to, when looking for and saving files.

We’re going to create a new project in RStudio:

+ `File` 
+ `New Project` 
+ `Empty project` 
+ browse for directory where you want to keep it 
+ type **r-geospatial** as the name of the project 
+`Create project`

### Tips for project organisation
+ **Raw data** is read only
+ **Cleaned data** as read only
+ **Generated output** is disposable
+ **Related data together** (Some GIS file formats are really 3-6 files that need to be kept together and have the same name, e.g. shapefiles)
+ Keep consistent **naming schema**
+ Name all files to reflect their content or function
+ Stage your scripts: Creating separate R scripts or Rmarkdown documents for different stages of a project

### Organising project/working directory

![](assets/img/rstudio_project_files.jpeg)
### Packages 
A great power of R lays in packages add-on sets of functions that are build by the community and once they go through a quality proccess they are available to download from a repository called CRAN. They need to be explicitly activated. 
Now, we will be using `tidyverse` package, which is actually a collection of useful packages. Another package that will be useful for us is `here`.

If you have have not installed this package earlier, please do so. You can check if you have it installed in the `Packages` pane in the bottom-right window.

```{r install-package, eval=FALSE}
install.packages('tidyverse')
install.packages('here')
```

You need to install package only once, but you will need to load it each time you want to use its functionalities. To do that you use `library()` command:

```{r load-package}
library(tidyverse)
library(here)

```

### `here()` package

![](../assets/img/here.png){height=500px}

<font size="3">*Credit*:[Allison horst](https://github.com/allisonhorst)</font>

You have created a project which is your working directory, and a number of subfolders, that will help you organise your project better. But now each time you will save or retrieve a file from those folders, you will need to specify the path from the folder your in (most likely scripts). That can become complicated and can become a reproducibility problem if the person using your code (e.g. future you) is working in a different subfolder. 

`here()` to the rescue! This package provides absolute paths from the root (main directory) of your project. 

```{r here}
here('data')
```


### Download files  - Should be send via email in the zipped file? Then this part can be skipped

#### Part 1: 
```{r download-files}
download.file('https://raw.githubusercontent.com/datacarpentry/r-intro-geospatial/master/_episodes_rmd/data/gapminder_data.csv', 'data/gapminder_data.csv', mode = 'wb')

```

#### Part 2: 
+ Download zip file by clicking on [this link](https://ndownloader.figshare.com/articles/2009586/versions/10)
+ Move the downloaded zip file to the data directory.
+ Once the data have been moved, unzip all files. 

# [Intro to R](https://datacarpentry.org/r-intro-geospatial/01-rstudio-intro/index.html)  (20+5 min)

## Use R as a calculator

```{r calculator}
1+100

12/7

3*5

```
## Comparing things 

```{r comparison}
1 == 1 # 1 equal to 1

1 != 2 # 1 not equal to 2

1 < 2 # 1 lower than 2

1 <= 1 # 1 lower than or equal to 1

1 > 0 # 1 greater than 0

1 >= -9 # 1 greater than or equal to -9

```

*If you want to test 'near equality' (small differences), use `all.equal()`.

## Variables and assignment

We can store values in variables using the assignment operator `<-`, like this:

```{r asignment-operator}
x <- 1/40
```

Notice that assignment does not print a value. Instead, we stored it for later in something called a variable. x now contains the value 0.025:
```{r asignment-operator2}
x
```

Look for the Environment tab in one of the panes of RStudio, and you will see that x and its value have appeared. 

Our variable x can be used in place of a number in any calculation that expects a number:
```{r use-variable}
sqrt(x)
```

Variables can be also ressigned:
```{r reassign}
x <- 100
x
```

You can use the 'old' value when reassigning the value
```{r reassign2}
x <- x + 1 #notice how RStudio updates its description of x on the top right tab
x
y <- x * 2 # you can use value stored in object x to create y
```


### Challenge 1
```{r ex1, class.source="bg-info"}
# What will be the value of each variable after each statement in the following program?

mass <- 47.5
age <- 122
mass <- mass * 2.3
age <- age - 20

```

### Challenge 2
```{r ex2, class.source="bg-info", eval = F}
# Compare mass to age. Is mass larger than age?

mass > age
```


# [Data Structures](https://datacarpentry.org/r-intro-geospatial/03-data-structures-part1/index.html) (40+15 min)

## Data types 
There are 6 main types: `numeric`, `integer`, `complex`, `logical`, `character`, and `factor`.
We will skip explanation of the `complex` data type for now. 

```{r data-types}
class(3.14) # a float number

class(1) # Although there are no decimal points, R still treats 1 as numeric/double/float
class(1L) # The L suffix forces the number to be an integer, since by default R uses float numbers


class(TRUE) # Logical value TRUE/FALSE

class('banana') # String of characters
class('1') # A number in quotation marks is also a character

class(factor('banana')) # factor  - a special data class that we will discuss later

```

## Vectors 

Vectors are arrays of values of a same data type. You can create vector with a `c()` function. 

```{r vectors}

numeric_vector <- c(2, 6, 3)
numeric_vector

character_vector <- c('banana', 'apple', 'orange')
character_vector

logical_vector <- c(TRUE, FALSE, TRUE)
logical_vector

```

### Challenge 3 (taken from [intro to R for social sciences](https://datacarpentry.org/r-socialsci/01-intro-to-r/index.html#exercise-3))

```{r ex3, class.source="bg-info"}
# What will happen in each of these examples? (hint: use class() to check the data type of your objects)

num_char <- c(1, 2, 3, "a")
num_logical <- c(1, 2, 3, TRUE)
char_logical <- c("a", "b", "c", TRUE)
tricky <- c(1, 2, 3, "4")

```

### Type coersion

This is something called type coercion, and it is the source of many surprises and the reason why we need to be aware of the basic data types and how R will interpret them. When R encounters a mix of types (here numeric and character) to be combined into a single vector, it will force them all to be the same type. 

The coercion rules go: `logical -> integer -> numeric -> character`.
You can try to force coercion against this flow using the `as.` functions:

```{r as-functions}
numeric_vector <- c(2, 6, 3)
numeric_vector

numeric_to_character <- as.character(numeric_vector)
numeric_to_character

back_to_numeric <- as.numeric(numeric_to_character)
back_to_numeric

```

### Combining vectors 

The combine function, c(), will also append things to an existing vector:

```{r combine-vectors}

ab_vector <- c('a', 'b')
ab_vector

abcd_vector <- c(ab_vector, 'DC')
abcd_vector

```

You can also make series of numbers:

```{r num-series}
my_series <- 1:10
my_series
```

### Inspecting vectors 

We can ask a few questions about vectors:

```{r}
my_series <- 1:100

head(my_series) # Shows the first 5 (or a chosen number) elements of the vectors
tail(my_series) # Shows the last 5 (or a chosen number) elements of the vectors

length(my_series) # Returns number of elements in the vector

class(my_series) # shows the data type of the elements in the vector
```

### Subsetting vectors

#### Subsetting through indices 
More often than not, you will need only specific elements of vectors. There are several ways to access them. We will look at it now. To access a data structure, you use square brackets `[]` and the position of the element.

```{r subsetting-vector}
my_letters <- c(letters[1:6])
my_letters[1] # the first element of the  vector
```

In many programming languages (C and Python, for example), the first element of a vector has an index of 0. In R, the first element is 1.


```{r subsetting-vector2}
my_letters[1:4] # 1-4 elements of the  vector

my_letters[c(1,3)] # first and third element of the  vector

```

In a similar way you can also exclude elements from the vector

```{r subsetting-excluding}
my_letters[-2] #  vector excluding the 2nd element

my_letters[-c(1,5)] #  vector excluding 1st and 5th element

my_letters[-(1:3)] #  vector excluding first 3 elements

```

### Challenge 4 
```{r ex4, class.source="bg-info"}
# Given the following code:

x <- c(5.4, 6.2, 7.1, 4.8, 7.5)
names(x) <- c('a', 'b', 'c', 'd', 'e')
print(x)
```

Come up with at least 3 different commands that will produce the following output:

```{r echo=F}
x[2:4]
```

#### Subsetting through logical operators

You can also use logical vectors to subset:

```{r subset-logical}
my_letters[c(TRUE, FALSE, TRUE, FALSE, TRUE)] # Returns only the elements of x that have 'TRUE' value on the corresponding position: 1,3,5

```
We can use this functionality to use comparison operators (remember that they return TRUE or FALSE?):
```{r}
my_floats <- c(5.4, 6.2, 7.1, 4.8, 7.5)

my_floats > 7 # This operation returns the vector of logical values, indicating if the condition is fulfilled for each element

my_floats[my_floats > 7] # Returns all the elements of y greater than 7

my_floats[my_floats > 7 | my_floats < 5] # Returns all the elements of y greater than 7 or lower than 5
my_floats[my_floats > 7 & my_floats < 7.5] # Returns all the elements of y greater than 7 and lower than 7.5

```

A common operation you want to perform is to remove all the missing values (in R denoted as `NA`). Let's have a look how to do it: 

```{r remove-na}
with_na <- c(1, 2, 1, 1, NA, 3) # vector including missing value)

is.na(with_na) # With missing values, you cannot compare them directly, you need to do it using is.na() function

without_na <- with_na[!is.na(with_na)] # The ! operator means negation ,i.e. not is.na(with_na)
without_na

```




## Factors (adapted from [Starting with Data](https://datacarpentry.org/r-socialsci/02-starting-with-data/index.html))

Another important data structure is called a factor. Factors look like character data, but are used to represent categorical information.

Factors create a structured relation between the different levels (values) of a categorical variable, such as days of the week or responses to a question in a survey. While factors look (and often behave) like character vectors, they are actually treated as integer vectors by R. So you need to be very careful when treating them as strings.

### Create factors
Once created, factors can only contain a pre-defined set of values, known as levels. 

```{r factor-create}

nordic_str <- c('Norway', 'Sweden', 'Norway', 'Denmark', 'Sweden')
nordic_str # regular character vectors printed out

nordic_cat <- factor(nordic_str) # factor() function converts a vector to factor data type
nordic_cat # With factors, R prints out additional information - 'Levels'

```

### Inspect factors
R will treat each unique value from a factor vector as a **level** and (silently) assign numerical values to it. This come in handy when performing statistical analysis. You can inspect and adapt levels of the factor. 

```{r factor-inspect}
levels(nordic_cat) # returns all levels of a factor vector.  

nlevels(nordic_cat) # returns number of levels in a vector
```

### Reorder levels
Note that R sorts the levels in the alphabetic order, not in the order of occurrence in the vector. R assigns value of 1 to level 'Denmark', 2 to 'Norway' and 3 to 'Sweden'. This is important as it can affect e.g. the order in which categories are displayed in a plot or which category is taken as a baseline in a statistical model.

You can reorder the categories using `factor()` function.

```{r factor-reorder}

nordic_cat <- factor(nordic_cat, levels = c('Norway' , 'Denmark', 'Sweden')) # now Norway should be the first category, Denmark second and Sweden third

nordic_cat

str(nordic_cat) # you can also inspect vectors with str() function. In facto vectors, it shows the underlying values of each category. You can also see the structure in the environment tab of RStudio.
```

### Note of caution 
Remember that once created, factors can only contain a pre-defined set of values, known as levels. 
It means that whenever you try to add something to the factor vector outside of this set, it will become an unknown/missing value detonated by R as `NA`.

```{r factor-missing-level}
nordic_str
nordic_cat2 <- factor(nordic_str, levels = c('Norway', 'Denmark'))
nordic_cat2 # since we have not included Sweden in the list of factor levels, it has become NA.
```


<!-- need to reduce this part by by 55 minutes -->
# [Exploring Data frames](https://datacarpentry.org/r-intro-geospatial/04-data-structures-part2/index.html) (20+10 min)

Now we turn to the bread-and-butter of working with R: working with tabular data. In R data are stored in a data structure called **data frames**.  

A data frame is the representation of data in the format of a **table** where the columns are **vectors** that all have the **same length**. 
Because columns are vectors, each column must contain a **single type of data** (e.g., characters, integers, factors). 
For example, here is a figure depicting a data frame comprising a numeric, a character, and a logical vector.

![](assets/img/data-frame.svg)

## Reading data

`read.csv()` is a function used to read coma separated data files (`.csv` format)). There are other functions for files separated with other delimiters. 
We're gonna read in the gap minder data set with information about countries' size, GDP and average life expectancy in different years.

```{r reading-data}
gapminder <- read.csv("data/gapminder_data.csv") 

```

## Exploring dataset
Let’s investigate the gapminder data frame a bit; the first thing we should always do is check out what the data looks like.

It is important to see if all the variables (columns) have the data type that we require. Otherwise we can run into trouble.

```{r inspecting-data-str}
str(gapminder) 

```
We can see that the `gapminder` object is a data.frame with `r nrow(gapminder)` observations/ rows and `r ncol(gapminder)` variables/columns. 
In each line after a `$` sign, we see the name of each column, its type and first few values. 


There are multiple ways to explore a data set. Here are just a few examples

```{r}
head(gapminder) # see first 5  rows of the data set
dim(gapminder) # get the dimensions of the data set (number of rows and columns)

colnames(gapminder) # column names 

summary(gapminder) # gives basic statistical information about each column. Information format differes by data type.

```

## Accessing columns, rows and cells

When you're analyzing a data set, you often need to access its specific elements.There are different way to go about it, and we will explore some of them.

One handy way to access a column is using it's name and a dollar sign `$`: 
```{r subset-dollar-sign}
country_vec <- gapminder$country  # Notation means: From dataset gapminder, give me column country. You can see that the column accessed in this way is just a vector of characters. 

head(country_vec)

```
Sometimes, however, you want to maintain a structure of a data frame. You can call the name of the column using it's name and square brackets  `[]`. This way you can also create a subset of your data set. 
```{r subset-name}
country_df<-gapminder["country"] 
head(country_df)

```

as in the case of vectors, we can use indices together with `[]` to select specific sections of the data set. 

```{r subset-indices}
gapminder[1:3,] # first 3 rows of the data frame

head(gapminder[,3]) # third column of the data set; returns a vector; equivalent to gapminder$pop

head(gapminder[3]) # equivalent to gapminder[,3]; returns a data frame; equivalent to gapminder['pop']

```


# [Data frame Manipulation with dplyr](https://datacarpentry.org/r-intro-geospatial/06-dplyr/index.html) (30+10 min)

## Packages
So far, we have been using functionalities available with R installation. Now, that we would like to move forward with our analysis, we can make use of packages - add-on sets of functions that need to be explicitly activated. Now, we will be using `tidyverse` package, which is actually a collection of useful packages. 

## Select
Let's start manipulating the data. 

First we will adapt our dataset, by keeping only the columns we're interested in using the `select()` function from `dplyr` package:

```{r dplyr-select}
year_country_gdp <- select(gapminder, year, country, gdpPercap) 

head(year_country_gdp)

```

## Pipe
Now, this is not the most common notation when working with `dplyr` package. `dplyr` offers an operator `%>%` called a pipe, which allows you build up a very complicated commands in a readable way. 

The `select()` statement with pipe would look like that:

```{r dplyr-pipe}

year_country_gdp <- gapminder %>% select(year,country,gdpPercap)

head(year_country_gdp)

```

First we define data set, then with the use of pipe we pass it on to the `select()` function. This way we can chain multiple functions together, which we will be doing now. 

## Filter

We already now how to select only the needed columns. But now, we also want to filter the data set via certain condition with `filter()` function. Instead doing it in separate steps , we can do it all together. 
In the `gapminder` data set, we want to see the results only for Europe. 
```{r}
year_country_gdp_euro <- gapminder %>% 
  filter(continent == "Europe") %>%
  select(year, country, gdpPercap)
```

### Challenge 5
<div class="alert alert-info">

Write a single command (which can span multiple lines and includes pipes) that will produce a dataframe that has the African values for life expectancy, country and year, but not for other Continents. How many rows does your dataframe have and why?
</div>
```{r ex5, class.source="bg-info", include = F}
year_country_lifeExp_Africa <- gapminder %>%
                           filter(continent=="Africa") %>%
                           select(year,country,lifeExp)

```



## Group and summarize
So far, we have created a dataset for one of the continents represented in the `gapminder` dataset. But rather than doing that, we want to know statistics about all of the continents, presented by group.

```{r dplyr-group}
gapminder %>% # select the dataset
  group_by(continent) %>% # group by continent
  summarize(mean_gdpPercap = mean(gdpPercap)) # summarize function creates statistics for the data set 

```

### Challenge 6
<div class="alert alert-info">

Calculate the average life expectancy per country. Which has the longest average life expectancy and which has the shortest average life expectancy?
</div>
```{r ex6 , class.source="bg-info", include=F}
lifeExp_bycountry <- gapminder %>%
   group_by(country) %>%
   summarize(mean_lifeExp=mean(lifeExp))


lifeExp_bycountry %>%
   filter(mean_lifeExp == min(mean_lifeExp) | mean_lifeExp == max(mean_lifeExp))
```


You can group by multiple columns:

```{r dplyr-group-multi}

gapminder %>%
  group_by(continent, year) %>%
  summarize(mean_gdpPercap = mean(gdpPercap))

```

On top of this, you can also make multiple summaries of those groups:
```{r dplyr-summ}
gdp_pop_bycontinents_byyear <- gapminder %>%
  group_by(continent,year) %>%
  summarize(
    mean_gdpPercap = mean(gdpPercap),
    sd_gdpPercap = sd(gdpPercap),
    mean_pop = mean(pop),
    sd_pop = sd(pop)
    )

```

## Frequencies

If you need a number of observations per group, you can use the `count()` function
```{r dplyr-count}

gapminder %>%
    group_by(continent) %>%
    count()

```

Sometimes you need the number of observations per group for your calculations. You can use `n()` function for this. 

```{r dplyr-n}
gapminder %>%
    group_by(continent) %>%
    summarize(
      n = n(),
      se_le = sd( lifeExp )/sqrt( n() ) 
      )
```

## Mutate

Frequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this we’ll use `mutate()`.

```{r dplyr-mutate}
gapminder_gdp <- gapminder %>%
  mutate(gdp_billion = gdpPercap*pop/10^9)

head(gapminder_gdp)

```


# [Introduction to Visualisation](https://datacarpentry.org/r-intro-geospatial/07-plot-ggplot2/index.html) (20+15 min)
Package `ggplot2` is a powerful plotting system. I will introduce key features of `ggplot`. Later today/ on Monday you will use this package to visualize geospatial data.
`gg` stands for grammar of graphics, the idea that three components needed to create a graph are:
- data
- aesthetics - coordinate system on which we map the data ( what is represented on x axis, what on y axis)
- geometries - visual representation of the data (points, bars, etc.)

fun part about `ggplot` is that you can then add additional layers to the plot providing more information and make it more beautiful. 

First, lets plot distribution of life expectancy in the `gapminder` dataset. 

```{r ggplot}

gapminder %>%  # data layer
  ggplot( aes(x = lifeExp)) + # aesthetics layer 
  geom_histogram() # geometry layer

```

You can see that in `ggplot` you use `+` as a pipe, to add layers. Within `ggplot` call, it is the only pipe that will work. 
But, it is possible to chain operations on a dataset with a pipe that we have already learned: `%>%` ( or `|>`) and follow them but ggplot grammar. 

Let's create another plot, this time only on a subset of observations:

```{r ggplot-col}
gapminder %>%  # we select a dataset
  filter(year == 2007, 
         continent == 'Americas') %>% # and filter it to keep only one year and one continent
  ggplot(aes(x = country, y = gdpPercap)) + # we create aesthetics, both x and y axis represent values of  columns
  geom_col() # we select a column graph as a geometry
```

Now, you can iteratively improve how the plot looks. For example, you might want to flip it, to better display the labels.

```{r ggplot-coord-flip}
gapminder %>%  
  filter(year == 2007, 
         continent == 'Americas') %>% 
  ggplot(aes(x = country, y = gdpPercap)) + 
  geom_col()+ 
  coord_flip()
```
One thing you might want to change here is the order in which countries are displayed. It would be easier to compare GDP per capita, if theY were showed in order. 
To do that, we need to reorder factor levels (you remember, we've already done this before).
the order of the levels will depend on another variable - GDP per capita.

```{r ggplot-color}
gapminder %>%  
  filter(year == 2007, 
         continent == 'Americas') %>% 
  mutate(country_reordered = fct_reorder(country, gdpPercap )) %>%
  ggplot(aes(x = country_reordered , y = gdpPercap)) + 
  geom_col() +
  coord_flip()

```


Let's make things more colorful - let's represent the average life expectancy of a country by color

```{r ggplot-colors}
gapminder %>%  
  filter(year == 2007, 
         continent == 'Americas') %>% 
  mutate(country_reordered = fct_reorder(country, gdpPercap )) %>%
  ggplot(aes(x = country_reordered, y = gdpPercap, fill = lifeExp   )) + # fill argument for coloring surfaces, color for points and lines
  geom_col()+ 
  coord_flip()


```

We can also adapt the color scale. Common choice that is used for its colorblind-proofness is `viridis` package.
```{r ggplot-colors-adapt}
plot_2007_amr <-  # this time let's save the plot in the object.
  gapminder %>%  
  filter(year == 2007, 
         continent == 'Americas') %>% 
  mutate(country_reordered = fct_reorder(country, gdpPercap )) %>%
  ggplot(aes(x = country_reordered, y = gdpPercap, fill = lifeExp   )) + # fill argument for coloring surfaces, color for points and lines
  geom_col()+ 
  coord_flip()+
  scale_fill_viridis_c()

```

Since we saved a plot as an object, nothing has been printed out. Just like with any other object in `R`, if you want to see it, you need to call it.  

```{r ggplot-call}
plot_2007_amr

```

Now we can make use of the saved object and add things to it.

Let's also give it a title and name the axes:
```{r ggplot-titles}
plot_2007_amr <- 
  plot_2007_amr +
  ggtitle('GDP per capita in Americas', subtitle = 'Year 2007') +
  xlab('Country')+
  ylab('GDP per capita')

plot_2007_amr
```

Once we are happy with our plot we can save it in a format of our choice. Remember to save it in the dedicated folder. 

```{r save plot}
ggsave(here('fig_output','plot_2007_amr.pdf') ) # By default, ggsave() saves the last displayed plot, but you can also explicitly name the plot you want to save

```


Another output of your work you want to save is a cleaned dataset. In your analysis, you can then load directly that dataset. Say we want to save the data only for Australia:

```{r writing-data}
gapminder_aus <- gapminder %>%  
  filter(country == 'Australia') 

write_csv(gapminder_aus, here('data_output', 'gapminder_australia.csv'))


```



